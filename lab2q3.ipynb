{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/opt/bitnami/python/bin/python\n",
    "# -*-coding:utf-8 -*\n",
    "import sys\n",
    "\n",
    "for line in sys.stdin: # reads from stdin\n",
    "    line = line.strip()\n",
    "    words = line.split()\n",
    "    for word1 in words:\n",
    "        for word2 in words:\n",
    "            if(word1 != word2):\n",
    "                print(word1+\"\\t\"+word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/opt/bitnami/python/bin/python\n",
    "# -*-coding:utf-8 -*\n",
    "\n",
    "import sys\n",
    "\n",
    "word2_count = 0\n",
    "word1_count = 0\n",
    "key = None\n",
    "value = None\n",
    "values = dict()\n",
    "for line in sys.stdin:\n",
    "    line = line.strip()\n",
    "#     print(line)\n",
    "    word1, word2 = line.split()\n",
    "    count = 1\n",
    "\n",
    "    # new key value pair\n",
    "    if key is None:\n",
    "        key = word1\n",
    "        value = word2\n",
    "    # same as previous pair\n",
    "    if word1 == key and word2 == value:\n",
    "        word2_count += count\n",
    "        word1_count += count\n",
    "    # different value, save the old value counts\n",
    "    if word1 == key and word2 != value:\n",
    "        word1_count += count\n",
    "        values[value] = word2_count\n",
    "        value = word2\n",
    "        word2_count = count\n",
    "    # new key, print the old key values\n",
    "    elif word1 != key:\n",
    "        values[value] = word2_count\n",
    "        for item in values:\n",
    "            print(key+\"\\t\"+item+\"\\t\"+str(values[item]/word1_count))\n",
    "        values.clear()\n",
    "        key = word1\n",
    "        value = word2\n",
    "        word2_count = count\n",
    "        word1_count = count\n",
    "\n",
    "if key is not None:\n",
    "    values[value] = word2_count\n",
    "    for item in values:\n",
    "            print(key+\"\\t\"+item+\"\\t\"+str(values[item]/word1_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cheese\tmilk\t1\r\n",
      "cheese\tbread\t1\r\n",
      "cheese\teggs\t1\r\n",
      "cheese\tcoffee\t1\r\n",
      "cheese\tmilk\t1\r\n",
      "milk\tcheese\t1\r\n",
      "milk\teggs\t1\r\n",
      "milk\tcoffee\t1\r\n",
      "milk\tcoke\t1\r\n",
      "milk\tcandy\t1\r\n",
      "milk\tbread\t1\r\n",
      "milk\tcheese\t1"
     ]
    }
   ],
   "source": [
    "!cat data/co.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cheese\tmilk\t0.2\r\n",
      "cheese\tbread\t0.2\r\n",
      "cheese\teggs\t0.2\r\n",
      "cheese\tcoffee\t0.2\r\n",
      "milk\tcheese\t0.14285714285714285\r\n",
      "milk\teggs\t0.14285714285714285\r\n",
      "milk\tcoffee\t0.14285714285714285\r\n",
      "milk\tcoke\t0.14285714285714285\r\n",
      "milk\tcandy\t0.14285714285714285\r\n",
      "milk\tbread\t0.14285714285714285\r\n"
     ]
    }
   ],
   "source": [
    "!cat data/co.txt | python reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /inputs\n",
      "rm: `/outputs': No such file or directory\n",
      "2020-10-29 05:21:35,643 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2020-10-29 05:21:37,080 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2020-10-29 05:21:37,869 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -rm -R /inputs\n",
    "!hadoop fs -rm -R /outputs\n",
    "!hadoop fs -mkdir -p /inputs\n",
    "!hadoop fs -mkdir -p /outputs\n",
    "!hadoop fs -put data /inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\r\n",
      "-rw-r--r--   3 root supergroup        164 2020-10-29 05:21 /inputs/data/co.txt\r\n",
      "-rw-r--r--   3 root supergroup         59 2020-10-29 05:21 /inputs/data/cosmall.txt\r\n",
      "-rw-r--r--   3 root supergroup    4167490 2020-10-29 05:21 /inputs/data/retail.dat\r\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls /inputs/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /outputs\n",
      "2020-10-29 21:14:47,366 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "packageJobJar: [/training/mapper.py, /training/reducer.py, /tmp/hadoop-unjar3417544907767511383/] [] /tmp/streamjob8113371379460189818.jar tmpDir=null\n",
      "2020-10-29 21:14:49,621 INFO client.RMProxy: Connecting to ResourceManager at resourcemanager/172.18.0.2:8032\n",
      "2020-10-29 21:14:50,193 INFO client.AHSProxy: Connecting to Application History server at historyserver/172.18.0.3:10200\n",
      "2020-10-29 21:14:50,282 INFO client.RMProxy: Connecting to ResourceManager at resourcemanager/172.18.0.2:8032\n",
      "2020-10-29 21:14:50,283 INFO client.AHSProxy: Connecting to Application History server at historyserver/172.18.0.3:10200\n",
      "2020-10-29 21:14:50,874 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1604005958251_0001\n",
      "2020-10-29 21:14:51,642 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2020-10-29 21:14:52,462 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2020-10-29 21:14:53,273 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2020-10-29 21:14:53,731 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "2020-10-29 21:14:54,218 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2020-10-29 21:14:54,518 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2020-10-29 21:14:54,607 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "2020-10-29 21:14:57,523 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2020-10-29 21:14:57,626 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1604005958251_0001\n",
      "2020-10-29 21:14:57,626 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2020-10-29 21:14:59,701 INFO conf.Configuration: resource-types.xml not found\n",
      "2020-10-29 21:14:59,702 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "2020-10-29 21:15:02,285 INFO impl.YarnClientImpl: Submitted application application_1604005958251_0001\n",
      "2020-10-29 21:15:03,374 INFO mapreduce.Job: The url to track the job: http://resourcemanager:8088/proxy/application_1604005958251_0001/\n",
      "2020-10-29 21:15:03,379 INFO mapreduce.Job: Running job: job_1604005958251_0001\n",
      "2020-10-29 21:24:26,758 INFO mapreduce.Job: Job job_1604005958251_0001 running in uber mode : false\n",
      "2020-10-29 21:24:26,888 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2020-10-29 21:25:43,849 INFO mapreduce.Job:  map 33% reduce 0%\n",
      "2020-10-29 21:25:49,000 INFO mapreduce.Job:  map 67% reduce 0%\n",
      "2020-10-29 21:25:52,303 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2020-10-29 21:26:29,598 INFO mapreduce.Job:  map 100% reduce 14%\n",
      "2020-10-29 21:26:34,617 INFO mapreduce.Job:  map 100% reduce 29%\n",
      "2020-10-29 21:26:39,648 INFO mapreduce.Job:  map 100% reduce 43%\n",
      "2020-10-29 21:26:44,682 INFO mapreduce.Job:  map 100% reduce 57%\n",
      "2020-10-29 21:27:19,659 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2020-10-29 21:27:25,811 INFO mapreduce.Job: Job job_1604005958251_0001 completed successfully\n",
      "2020-10-29 21:27:43,803 INFO mapreduce.Job: Counters: 55\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=369\n",
      "\t\tFILE: Number of bytes written=2100831\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=281\n",
      "\t\tHDFS: Number of bytes written=529\n",
      "\t\tHDFS: Number of read operations=41\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=14\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tKilled reduce tasks=1\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=7\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=492316\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=454576\n",
      "\t\tTotal time spent by all map tasks (ms)=123079\n",
      "\t\tTotal time spent by all reduce tasks (ms)=56822\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=123079\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=56822\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=504131584\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=465485824\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=3\n",
      "\t\tMap output records=24\n",
      "\t\tMap output bytes=304\n",
      "\t\tMap output materialized bytes=436\n",
      "\t\tInput split bytes=192\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=22\n",
      "\t\tReduce shuffle bytes=436\n",
      "\t\tReduce input records=24\n",
      "\t\tReduce output records=22\n",
      "\t\tSpilled Records=48\n",
      "\t\tShuffled Maps =14\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=14\n",
      "\t\tGC time elapsed (ms)=926\n",
      "\t\tCPU time spent (ms)=7840\n",
      "\t\tPhysical memory (bytes) snapshot=1560498176\n",
      "\t\tVirtual memory (bytes) snapshot=68675047424\n",
      "\t\tTotal committed heap usage (bytes)=1178075136\n",
      "\t\tPeak Map Physical memory (bytes)=210284544\n",
      "\t\tPeak Map Virtual memory (bytes)=5063417856\n",
      "\t\tPeak Reduce Physical memory (bytes)=175120384\n",
      "\t\tPeak Reduce Virtual memory (bytes)=8376668160\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=89\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=529\n",
      "2020-10-29 21:27:43,804 INFO streaming.StreamJob: Output directory: /outputs/\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -rm -R /outputs\n",
    "!hadoop jar /opt/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-3.2.1.jar \\\n",
    "    -D stream.num.map.output.key.fields=2 \\\n",
    "    -D mapreduce.partition.keypartitioner.options=-k1,1 \\\n",
    "    -D mapreduce.job.reduces=7 \\\n",
    "    -file $PWD/mapper.py\\\n",
    "    -file $PWD/reducer.py\\\n",
    "    -mapper mapper.py \\\n",
    "    -reducer reducer.py \\\n",
    "    -input /inputs/data/cosmall.txt \\\n",
    "    -output /outputs/ \\\n",
    "    -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 items\r\n",
      "-rw-r--r--   3 root supergroup          0 2020-10-29 21:27 /outputs/_SUCCESS\r\n",
      "drwxr-xr-x   - root supergroup          0 2020-10-29 21:27 /outputs/_temporary\r\n",
      "-rw-r--r--   3 root supergroup    9404342 2020-10-29 21:32 /outputs/part-00000\r\n",
      "-rw-r--r--   3 root supergroup         95 2020-10-29 21:26 /outputs/part-00001\r\n",
      "-rw-r--r--   3 root supergroup         30 2020-10-29 21:26 /outputs/part-00002\r\n",
      "-rw-r--r--   3 root supergroup         32 2020-10-29 21:26 /outputs/part-00003\r\n",
      "-rw-r--r--   3 root supergroup         91 2020-10-29 21:26 /outputs/part-00004\r\n",
      "-rw-r--r--   3 root supergroup          0 2020-10-29 21:26 /outputs/part-00005\r\n",
      "-rw-r--r--   3 root supergroup         29 2020-10-29 21:27 /outputs/part-00006\r\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls /outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-29 21:32:34,041 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "cheese\tbread\t0.2\n",
      "cheese\tcoffee\t0.2\n",
      "cheese\teggs\t0.2\n",
      "cheese\tmilk\t0.4\n",
      "milk\tbread\t0.14285714285714285\n",
      "milk\tcandy\t0.14285714285714285\n",
      "milk\tcheese\t0.2857142857142857\n",
      "milk\tcoffee\t0.14285714285714285\n",
      "milk\tcoke\t0.14285714285714285\n",
      "milk\teggs\t0.14285714285714285\n",
      "2020-10-29 21:32:39,138 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "coffee\tcheese\t0.3333333333333333\n",
      "coffee\teggs\t0.3333333333333333\n",
      "coffee\tmilk\t0.3333333333333333\n",
      "2020-10-29 21:32:43,200 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "candy\tcoke\t0.5\n",
      "candy\tmilk\t0.5\n",
      "2020-10-29 21:32:57,829 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "bread\tcheese\t0.5\n",
      "bread\tmilk\t0.5\n",
      "2020-10-29 21:33:02,175 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "eggs\tcheese\t0.3333333333333333\n",
      "eggs\tcoffee\t0.3333333333333333\n",
      "eggs\tmilk\t0.3333333333333333\n",
      "2020-10-29 21:33:10,943 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "coke\tcandy\t0.5\n",
      "coke\tmilk\t0.5\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -cat /outputs/part-00000\n",
    "!hadoop fs -cat /outputs/part-00001\n",
    "!hadoop fs -cat /outputs/part-00002\n",
    "!hadoop fs -cat /outputs/part-00003\n",
    "!hadoop fs -cat /outputs/part-00004\n",
    "!hadoop fs -cat /outputs/part-00005\n",
    "!hadoop fs -cat /outputs/part-00006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /outputs\n",
      "2020-10-29 21:33:38,216 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "packageJobJar: [/training/mapper.py, /training/reducer.py, /tmp/hadoop-unjar7364661987132366336/] [] /tmp/streamjob4101167826217886714.jar tmpDir=null\n",
      "2020-10-29 21:33:42,376 INFO client.RMProxy: Connecting to ResourceManager at resourcemanager/172.18.0.2:8032\n",
      "2020-10-29 21:33:45,317 INFO client.AHSProxy: Connecting to Application History server at historyserver/172.18.0.3:10200\n",
      "2020-10-29 21:33:45,358 INFO client.RMProxy: Connecting to ResourceManager at resourcemanager/172.18.0.2:8032\n",
      "2020-10-29 21:33:45,359 INFO client.AHSProxy: Connecting to Application History server at historyserver/172.18.0.3:10200\n",
      "2020-10-29 21:33:46,627 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1604005958251_0002\n",
      "2020-10-29 21:33:48,142 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2020-10-29 21:33:48,692 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2020-10-29 21:33:49,727 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2020-10-29 21:33:50,816 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "2020-10-29 21:33:51,474 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2020-10-29 21:33:51,997 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2020-10-29 21:33:52,506 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "2020-10-29 21:33:53,219 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2020-10-29 21:33:53,408 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1604005958251_0002\n",
      "2020-10-29 21:33:53,408 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2020-10-29 21:33:53,908 INFO conf.Configuration: resource-types.xml not found\n",
      "2020-10-29 21:33:53,909 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "2020-10-29 21:33:57,811 INFO impl.YarnClientImpl: Application submission is not finished, submitted application application_1604005958251_0002 is still in SUBMITTED\n",
      "2020-10-29 21:33:58,356 INFO impl.YarnClientImpl: Submitted application application_1604005958251_0002\n",
      "2020-10-29 21:33:58,580 INFO mapreduce.Job: The url to track the job: http://resourcemanager:8088/proxy/application_1604005958251_0002/\n",
      "2020-10-29 21:33:58,582 INFO mapreduce.Job: Running job: job_1604005958251_0002\n",
      "2020-10-29 21:37:49,764 INFO mapreduce.Job: Job job_1604005958251_0002 running in uber mode : false\n",
      "2020-10-29 21:37:49,765 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2020-10-29 21:38:51,308 INFO mapreduce.Job:  map 8% reduce 0%\n",
      "2020-10-29 21:38:55,190 INFO mapreduce.Job:  map 15% reduce 0%\n",
      "2020-10-29 21:39:06,259 INFO mapreduce.Job:  map 29% reduce 0%\n",
      "2020-10-29 21:39:13,750 INFO mapreduce.Job:  map 36% reduce 0%\n",
      "2020-10-29 21:39:16,659 INFO mapreduce.Job:  map 40% reduce 0%\n",
      "2020-10-29 21:39:19,894 INFO mapreduce.Job:  map 46% reduce 0%\n",
      "2020-10-29 21:39:24,679 INFO mapreduce.Job:  map 59% reduce 0%\n",
      "2020-10-29 21:39:25,945 INFO mapreduce.Job:  map 67% reduce 0%\n",
      "2020-10-29 21:39:38,056 INFO mapreduce.Job:  map 81% reduce 0%\n",
      "2020-10-29 21:39:44,737 INFO mapreduce.Job:  map 93% reduce 0%\n",
      "2020-10-29 21:39:49,059 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2020-10-29 21:41:05,346 INFO mapreduce.Job:  map 100% reduce 4%\n",
      "2020-10-29 21:41:14,922 INFO mapreduce.Job:  map 100% reduce 8%\n",
      "2020-10-29 21:41:37,003 INFO mapreduce.Job:  map 100% reduce 12%\n",
      "2020-10-29 21:41:47,478 INFO mapreduce.Job:  map 100% reduce 16%\n",
      "2020-10-29 21:41:58,140 INFO mapreduce.Job:  map 100% reduce 20%\n",
      "2020-10-29 21:42:11,284 INFO mapreduce.Job:  map 100% reduce 24%\n",
      "2020-10-29 21:42:23,159 INFO mapreduce.Job:  map 100% reduce 28%\n",
      "2020-10-29 21:42:32,464 INFO mapreduce.Job:  map 100% reduce 32%\n",
      "2020-10-29 21:42:40,531 INFO mapreduce.Job:  map 100% reduce 36%\n",
      "2020-10-29 21:42:47,908 INFO mapreduce.Job:  map 100% reduce 40%\n",
      "2020-10-29 21:42:56,500 INFO mapreduce.Job:  map 100% reduce 44%\n",
      "2020-10-29 21:43:06,016 INFO mapreduce.Job:  map 100% reduce 48%\n",
      "2020-10-29 21:43:14,275 INFO mapreduce.Job:  map 100% reduce 52%\n",
      "2020-10-29 21:43:23,929 INFO mapreduce.Job:  map 100% reduce 56%\n",
      "2020-10-29 21:43:31,261 INFO mapreduce.Job:  map 100% reduce 60%\n",
      "2020-10-29 21:43:39,664 INFO mapreduce.Job:  map 100% reduce 64%\n",
      "2020-10-29 21:43:46,927 INFO mapreduce.Job:  map 100% reduce 68%\n",
      "2020-10-29 21:43:56,027 INFO mapreduce.Job:  map 100% reduce 72%\n",
      "2020-10-29 21:44:04,247 INFO mapreduce.Job:  map 100% reduce 76%\n",
      "2020-10-29 21:44:13,371 INFO mapreduce.Job:  map 100% reduce 80%\n",
      "2020-10-29 21:44:20,685 INFO mapreduce.Job:  map 100% reduce 84%\n",
      "2020-10-29 21:44:29,011 INFO mapreduce.Job:  map 100% reduce 88%\n",
      "2020-10-29 21:44:37,404 INFO mapreduce.Job:  map 100% reduce 92%\n",
      "2020-10-29 21:44:46,106 INFO mapreduce.Job:  map 100% reduce 96%\n",
      "2020-10-29 21:44:54,676 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2020-10-29 21:45:06,659 INFO mapreduce.Job: Job job_1604005958251_0002 completed successfully\n",
      "2020-10-29 21:45:21,131 INFO mapreduce.Job: Counters: 55\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=51650031\n",
      "\t\tFILE: Number of bytes written=82693534\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=4171776\n",
      "\t\tHDFS: Number of bytes written=226255835\n",
      "\t\tHDFS: Number of read operations=131\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=73\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tKilled reduce tasks=1\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=25\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=907772\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=1769736\n",
      "\t\tTotal time spent by all map tasks (ms)=226943\n",
      "\t\tTotal time spent by all reduce tasks (ms)=221217\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=226943\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=221217\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=929558528\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=1812209664\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=88162\n",
      "\t\tMap output records=14328670\n",
      "\t\tMap output bytes=145401094\n",
      "\t\tMap output materialized bytes=25066841\n",
      "\t\tInput split bytes=190\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=7173594\n",
      "\t\tReduce shuffle bytes=25066841\n",
      "\t\tReduce input records=14328670\n",
      "\t\tReduce output records=7173594\n",
      "\t\tSpilled Records=42986010\n",
      "\t\tShuffled Maps =50\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=50\n",
      "\t\tGC time elapsed (ms)=12015\n",
      "\t\tCPU time spent (ms)=150000\n",
      "\t\tPhysical memory (bytes) snapshot=5888708608\n",
      "\t\tVirtual memory (bytes) snapshot=219462725632\n",
      "\t\tTotal committed heap usage (bytes)=4057989120\n",
      "\t\tPeak Map Physical memory (bytes)=513609728\n",
      "\t\tPeak Map Virtual memory (bytes)=10043179008\n",
      "\t\tPeak Reduce Physical memory (bytes)=228265984\n",
      "\t\tPeak Reduce Virtual memory (bytes)=8394706944\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=4171586\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=226255835\n",
      "2020-10-29 21:45:21,230 INFO streaming.StreamJob: Output directory: /outputs/\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -rm -R /outputs\n",
    "!hadoop jar /opt/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-3.2.1.jar \\\n",
    "    -D stream.num.map.output.key.fields=2 \\\n",
    "    -D mapreduce.partition.keypartitioner.options=-k1,1 \\\n",
    "    -D mapreduce.job.reduces=25 \\\n",
    "    -file $PWD/mapper.py\\\n",
    "    -file $PWD/reducer.py\\\n",
    "    -mapper mapper.py \\\n",
    "    -reducer reducer.py \\\n",
    "    -input /inputs/data/retail.dat \\\n",
    "    -output /outputs/ \\\n",
    "    -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26 items\r\n",
      "-rw-r--r--   3 root supergroup          0 2020-10-29 21:44 /outputs/_SUCCESS\r\n",
      "-rw-r--r--   3 root supergroup    9404342 2020-10-29 21:41 /outputs/part-00000\r\n",
      "-rw-r--r--   3 root supergroup    9496011 2020-10-29 21:41 /outputs/part-00001\r\n",
      "-rw-r--r--   3 root supergroup    8420049 2020-10-29 21:41 /outputs/part-00002\r\n",
      "-rw-r--r--   3 root supergroup    9975371 2020-10-29 21:41 /outputs/part-00003\r\n",
      "-rw-r--r--   3 root supergroup    8790278 2020-10-29 21:41 /outputs/part-00004\r\n",
      "-rw-r--r--   3 root supergroup    8800016 2020-10-29 21:42 /outputs/part-00005\r\n",
      "-rw-r--r--   3 root supergroup    8943834 2020-10-29 21:42 /outputs/part-00006\r\n",
      "-rw-r--r--   3 root supergroup    8681714 2020-10-29 21:42 /outputs/part-00007\r\n",
      "-rw-r--r--   3 root supergroup    7965952 2020-10-29 21:42 /outputs/part-00008\r\n",
      "-rw-r--r--   3 root supergroup    9212994 2020-10-29 21:42 /outputs/part-00009\r\n",
      "-rw-r--r--   3 root supergroup    9237805 2020-10-29 21:42 /outputs/part-00010\r\n",
      "-rw-r--r--   3 root supergroup    9468070 2020-10-29 21:43 /outputs/part-00011\r\n",
      "-rw-r--r--   3 root supergroup   10307709 2020-10-29 21:43 /outputs/part-00012\r\n",
      "-rw-r--r--   3 root supergroup    9589654 2020-10-29 21:43 /outputs/part-00013\r\n",
      "-rw-r--r--   3 root supergroup    8509345 2020-10-29 21:43 /outputs/part-00014\r\n",
      "-rw-r--r--   3 root supergroup    9422903 2020-10-29 21:43 /outputs/part-00015\r\n",
      "-rw-r--r--   3 root supergroup    8863944 2020-10-29 21:43 /outputs/part-00016\r\n",
      "-rw-r--r--   3 root supergroup    9142606 2020-10-29 21:43 /outputs/part-00017\r\n",
      "-rw-r--r--   3 root supergroup    9640117 2020-10-29 21:44 /outputs/part-00018\r\n",
      "-rw-r--r--   3 root supergroup    9410627 2020-10-29 21:44 /outputs/part-00019\r\n",
      "-rw-r--r--   3 root supergroup    8398247 2020-10-29 21:44 /outputs/part-00020\r\n",
      "-rw-r--r--   3 root supergroup    8215657 2020-10-29 21:44 /outputs/part-00021\r\n",
      "-rw-r--r--   3 root supergroup    8962999 2020-10-29 21:44 /outputs/part-00022\r\n",
      "-rw-r--r--   3 root supergroup    8675854 2020-10-29 21:44 /outputs/part-00023\r\n",
      "-rw-r--r--   3 root supergroup    8719737 2020-10-29 21:44 /outputs/part-00024\r\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls /outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-29 21:55:34,937 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "9982\t38\t0.0625\n",
      "9982\t479\t0.0625\n",
      "9982\t48\t0.0625\n",
      "9982\t4911\t0.0625\n",
      "9982\t5782\t0.0625\n",
      "9982\t623\t0.0625\n",
      "9982\t6340\t0.0625\n",
      "9982\t9\t0.0625\n",
      "9982\t9223\t0.0625\n",
      "9982\t961\t0.0625\n",
      "2020-10-29 21:55:38,220 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "999\t991\t0.003048780487804878\n",
      "999\t992\t0.003048780487804878\n",
      "999\t993\t0.018292682926829267\n",
      "999\t994\t0.003048780487804878\n",
      "999\t9949\t0.003048780487804878\n",
      "999\t995\t0.003048780487804878\n",
      "999\t996\t0.009146341463414634\n",
      "999\t997\t0.003048780487804878\n",
      "999\t998\t0.006097560975609756\n",
      "999\t9992\t0.003048780487804878\n",
      "2020-10-29 21:55:42,164 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "9943\t987\t0.004901960784313725\n",
      "9984\t1026\t0.1111111111111111\n",
      "9984\t1543\t0.1111111111111111\n",
      "9984\t2563\t0.1111111111111111\n",
      "9984\t2870\t0.1111111111111111\n",
      "9984\t3850\t0.1111111111111111\n",
      "9984\t39\t0.1111111111111111\n",
      "9984\t41\t0.1111111111111111\n",
      "9984\t6283\t0.1111111111111111\n",
      "9984\t9983\t0.1111111111111111\n",
      "2020-10-29 21:55:45,310 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "9985\t8447\t0.003257328990228013\n",
      "9985\t854\t0.003257328990228013\n",
      "9985\t860\t0.003257328990228013\n",
      "9985\t8691\t0.003257328990228013\n",
      "9985\t885\t0.003257328990228013\n",
      "9985\t89\t0.003257328990228013\n",
      "9985\t8985\t0.003257328990228013\n",
      "9985\t9\t0.003257328990228013\n",
      "9985\t9061\t0.003257328990228013\n",
      "9985\t924\t0.003257328990228013\n",
      "2020-10-29 21:55:48,612 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "9986\t9510\t0.0023094688221709007\n",
      "9986\t956\t0.0023094688221709007\n",
      "9986\t9628\t0.0023094688221709007\n",
      "9986\t976\t0.0023094688221709007\n",
      "9986\t986\t0.0023094688221709007\n",
      "9986\t987\t0.0023094688221709007\n",
      "9986\t9887\t0.0023094688221709007\n",
      "9986\t9969\t0.0023094688221709007\n",
      "9986\t997\t0.0023094688221709007\n",
      "9990\t32\t1.0\n",
      "2020-10-29 21:55:52,278 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "9991\t89\t0.004878048780487805\n",
      "9991\t9\t0.004878048780487805\n",
      "9991\t91\t0.004878048780487805\n",
      "9991\t9547\t0.004878048780487805\n",
      "9991\t971\t0.004878048780487805\n",
      "9991\t9739\t0.004878048780487805\n",
      "9991\t976\t0.004878048780487805\n",
      "9991\t981\t0.004878048780487805\n",
      "9991\t9833\t0.004878048780487805\n",
      "9991\t9843\t0.004878048780487805\n",
      "2020-10-29 21:55:55,385 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "9992\t984\t0.005291005291005291\n",
      "9992\t985\t0.005291005291005291\n",
      "9992\t986\t0.005291005291005291\n",
      "9992\t987\t0.010582010582010581\n",
      "9992\t990\t0.010582010582010581\n",
      "9992\t991\t0.005291005291005291\n",
      "9992\t993\t0.010582010582010581\n",
      "9992\t997\t0.005291005291005291\n",
      "9992\t999\t0.005291005291005291\n",
      "9992\t9993\t0.005291005291005291\n",
      "2020-10-29 21:55:59,078 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "9993\t4887\t0.041666666666666664\n",
      "9993\t5557\t0.041666666666666664\n",
      "9993\t585\t0.041666666666666664\n",
      "9993\t772\t0.041666666666666664\n",
      "9993\t785\t0.041666666666666664\n",
      "9993\t7873\t0.041666666666666664\n",
      "9993\t846\t0.041666666666666664\n",
      "9993\t907\t0.041666666666666664\n",
      "9993\t91\t0.041666666666666664\n",
      "9993\t9992\t0.041666666666666664\n",
      "2020-10-29 21:56:03,137 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "9994\t8620\t0.005154639175257732\n",
      "9994\t878\t0.005154639175257732\n",
      "9994\t9\t0.005154639175257732\n",
      "9994\t9059\t0.005154639175257732\n",
      "9994\t9304\t0.005154639175257732\n",
      "9994\t942\t0.005154639175257732\n",
      "9994\t96\t0.005154639175257732\n",
      "9994\t975\t0.005154639175257732\n",
      "9994\t9798\t0.005154639175257732\n",
      "9994\t986\t0.005154639175257732\n",
      "2020-10-29 21:56:06,756 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "9995\t4990\t0.019230769230769232\n",
      "9995\t544\t0.019230769230769232\n",
      "9995\t549\t0.019230769230769232\n",
      "9995\t5786\t0.019230769230769232\n",
      "9995\t595\t0.019230769230769232\n",
      "9995\t6413\t0.019230769230769232\n",
      "9995\t6866\t0.019230769230769232\n",
      "9995\t8559\t0.019230769230769232\n",
      "9995\t9304\t0.019230769230769232\n",
      "9995\t9996\t0.019230769230769232\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -cat /outputs/part-00000 | tail\n",
    "!hadoop fs -cat /outputs/part-00001 | tail\n",
    "!hadoop fs -cat /outputs/part-00002 | tail\n",
    "!hadoop fs -cat /outputs/part-00003 | tail\n",
    "!hadoop fs -cat /outputs/part-00004 | tail\n",
    "!hadoop fs -cat /outputs/part-00005 | tail\n",
    "!hadoop fs -cat /outputs/part-00006 | tail\n",
    "!hadoop fs -cat /outputs/part-00007 | tail\n",
    "!hadoop fs -cat /outputs/part-00008 | tail\n",
    "!hadoop fs -cat /outputs/part-00009 | tail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
